{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1495d952-75a4-48ba-9758-8386ccb6b906",
   "metadata": {},
   "source": [
    "# Machine Learning 2 Assignment 3\n",
    "\n",
    "No chatGPT or Copilot was involved in the making at whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ea486b5-a964-49d6-83df-c4bf3a91de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import wandb\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef6eda7-f6ef-4362-827c-1d16c0d52b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "\n",
    "    def read_data(self):\n",
    "        # Need to insert train csv with file name and correct label \n",
    "        train_label = pd.read_csv('/Users/jason/Projects/MachineLearningProjects/klanguage/train.csv')\n",
    "        _1 = []\n",
    "        _2 = []\n",
    "        train_idx = []\n",
    "        val_idx = []\n",
    "        test_idx = []\n",
    "        train_size = len(train_label)\n",
    "        self.val_ratio = 0.2\n",
    "        split_idx = int(np.floor(self.val_ratio * train_size))\n",
    "        for i in train_label.values:\n",
    "            _1.append(i[0])\n",
    "            train_idx.append(i[1])\n",
    "\n",
    "        train_idx, val_idx = train_idx[split_idx:], train_idx[:split_idx]\n",
    "\n",
    "        return train_idx, val_idx\n",
    "\n",
    "    def getLen(self, data_path, train):\n",
    "        n = 0\n",
    "        if train:\n",
    "            for i in glob.glob(data_path + '/*'):\n",
    "                n += 1\n",
    "            return int(np.floor(n * (1 - self.val_ratio)))\n",
    "        else:\n",
    "            for i in glob.glob(data_path + '/*'):\n",
    "                n += 1\n",
    "            return int(np.floor(n * self.val_ratio))\n",
    "\n",
    "    def __init__(self, root_directory, train, transform=None):\n",
    "        super(CustomImageDataset, self).__init__()\n",
    "        self.root_directory = root_directory\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.train_label, self.val_label = self.read_data()\n",
    "        self.val_ratio = 0.2\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return self.getLen(self.root_directory, train=True)\n",
    "        else:\n",
    "            return self.getLen(self.root_directory, train=False)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            desired_width = 3\n",
    "            number_str = str(idx).zfill(desired_width)\n",
    "            img = Image.open(train_data_path + f'/{number_str}.jpg')\n",
    "            if transforms is not None:\n",
    "                img = self.transform(img)\n",
    "            return img, self.train_label[idx]\n",
    "        else:\n",
    "            desired_width = 3\n",
    "            number_str = str(idx).zfill(desired_width)\n",
    "            img = Image.open(train_data_path + f'/{number_str}.jpg')\n",
    "            if transforms is not None:\n",
    "                img = self.transform(img)\n",
    "            return img, self.val_label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9058f2a3-f112-45f3-a82b-22f7fce25f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testCustomImage(Dataset):\n",
    "    def getidx(self):\n",
    "        test_idx = []\n",
    "        # Needs to insert Test csv directory\n",
    "        test_dir = pd.read_csv('/Users/jason/Projects/MachineLearningProjects/klanguage/test.csv')\n",
    "        for i in test_dir.values:\n",
    "            test_idx.append(i[0])\n",
    "        return test_idx\n",
    "    def getLen(self, data_path):\n",
    "        n = 0\n",
    "        for i in glob.glob(data_path + '/*'):\n",
    "            n += 1\n",
    "        return n\n",
    "    def __init__(self, dir,  transform=None):\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        self.label = self.getidx()\n",
    "    def __getitem__(self, idx):\n",
    "        desired_width = 3\n",
    "        number_str = str(idx).zfill(desired_width)\n",
    "        img = Image.open(train_data_path + f'/{number_str}.jpg')\n",
    "        if transforms is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.label[idx]\n",
    "    def __len__(self):\n",
    "        return self.getLen(self.dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a98a240-79a7-40ba-a5ab-6bdb144d9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(14 * 14 * 256, 625, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.2))\n",
    "        self.layer6 = torch.nn.Linear(625, 11, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6061bd53-17f4-41fd-87d7-a257ac1d4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224), antialias=None),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224), antialias=None),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07438c70-cffe-4fb3-b26a-a275b28e0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "training_epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4442413-201e-47da-b176-95773fc0678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to appropriate directory when checking \n",
    "train_data_path = '/Users/jason/Projects/MachineLearningProjects/klanguage/train'\n",
    "test_data_path = '/Users/jason/Projects/MachineLearningProjects/klanguage/test'\n",
    "train_data = CustomImageDataset(train_data_path, train=True, transform=train_transform)\n",
    "val_data = CustomImageDataset(train_data_path, train=False, transform=val_transform)\n",
    "test_data = testCustomImage(test_data_path, transform=val_transform)\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d56fcf1e-8c3c-4285-8d56-e1aee51a45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(modelc, loss_fun, optimizerc):\n",
    "    size = len(train_data)\n",
    "    # modelc.to(device)\n",
    "    modelc.train()\n",
    "    n = 1\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        # Compute prediction and loss\n",
    "        # X.to(device)\n",
    "        # y.to(device)\n",
    "        pred = modelc(X)\n",
    "        loss = loss_fun(pred, y)\n",
    "        \n",
    "        optimizerc.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizerc.step()\n",
    "\n",
    "        # based on lab session\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= batch_size\n",
    "    train_acc /= size\n",
    "    print(f\"Train Error: \\n Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4583f14-a4ed-4359-8c58-51403e76a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(modelc, loss_fun):\n",
    "    print(\"Validation Start\")\n",
    "    print(\"---------------------\")\n",
    "    modelc.eval()\n",
    "    size = len(val_data)\n",
    "    num_batches = len(val_loader)\n",
    "    validity_loss, correct = 0, 0\n",
    "    validation_loss, validation_acc = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "\n",
    "            pred = model(X)\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            validation_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    validation_loss /= batch_size\n",
    "    validation_acc /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*validation_acc):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
    "\n",
    "    return validation_loss, validation_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714f6187-d549-4ff8-b9b8-65cdf507b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testw(modelc):\n",
    "    modelc.eval()\n",
    "    list_file = list(range(len(test_data)))\n",
    "    address = '/Users/jason/Projects/MachineLearningProjects/klanguage/'\n",
    "    list_a=[]\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            pred = modelc(X)\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            list_a.append(predicted.tolist())\n",
    "            np_list = np.array(list_a)\n",
    "        submission = pd.DataFrame({'file_name': list_file , 'label': np_list.ravel()})\n",
    "        submission.to_csv(path_or_buf=address + 'test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ddfc629-e010-4d76-a457-fc92fffe7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "# model.to(device)\n",
    "# print(f'device: {device}')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.005, momentum=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e4ff35e-98b3-49d2-8985-8a8fb37084e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Training loss: 2.387368  [   64/  621] at step1\n",
      "Time took for step [1]: 0.29 mins\n",
      "Time took for step [2]: 0.65 mins\n",
      "Time took for step [3]: 1.00 mins\n",
      "Time took for step [4]: 1.32 mins\n",
      "Time took for step [5]: 1.66 mins\n",
      "Time took for step [6]: 2.00 mins\n",
      "Time took for step [7]: 2.36 mins\n",
      "Time took for step [8]: 2.71 mins\n",
      "Time took for step [9]: 3.05 mins\n",
      "Time took for step [10]: 3.28 mins\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Training loss: 2.109366  [   64/  621] at step1\n",
      "Time took for step [1]: 0.33 mins\n",
      "Time took for step [2]: 0.65 mins\n",
      "Time took for step [3]: 0.98 mins\n",
      "Time took for step [4]: 1.32 mins\n",
      "Time took for step [5]: 1.65 mins\n",
      "Time took for step [6]: 1.96 mins\n",
      "Time took for step [7]: 2.29 mins\n",
      "Time took for step [8]: 2.62 mins\n",
      "Time took for step [9]: 2.97 mins\n",
      "Time took for step [10]: 3.20 mins\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Training loss: 2.039149  [   64/  621] at step1\n",
      "Time took for step [1]: 0.32 mins\n",
      "Time took for step [2]: 0.71 mins\n",
      "Time took for step [3]: 1.17 mins\n",
      "Time took for step [4]: 1.56 mins\n",
      "Time took for step [5]: 1.99 mins\n",
      "Time took for step [6]: 2.41 mins\n",
      "Time took for step [7]: 2.79 mins\n",
      "Time took for step [8]: 3.15 mins\n",
      "Time took for step [9]: 3.49 mins\n",
      "Time took for step [10]: 3.73 mins\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Training loss: 1.814973  [   64/  621] at step1\n",
      "Time took for step [1]: 0.36 mins\n",
      "Time took for step [2]: 0.72 mins\n",
      "Time took for step [3]: 1.09 mins\n",
      "Time took for step [4]: 1.45 mins\n",
      "Time took for step [5]: 1.85 mins\n",
      "Time took for step [6]: 2.26 mins\n",
      "Time took for step [7]: 2.62 mins\n",
      "Time took for step [8]: 2.97 mins\n",
      "Time took for step [9]: 3.35 mins\n",
      "Time took for step [10]: 3.62 mins\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Training loss: 1.855221  [   64/  621] at step1\n",
      "Time took for step [1]: 0.33 mins\n",
      "Time took for step [2]: 0.71 mins\n",
      "Time took for step [3]: 1.12 mins\n",
      "Time took for step [4]: 1.45 mins\n",
      "Time took for step [5]: 1.87 mins\n",
      "Time took for step [6]: 2.28 mins\n",
      "Time took for step [7]: 2.69 mins\n",
      "Time took for step [8]: 3.10 mins\n",
      "Time took for step [9]: 3.52 mins\n",
      "Time took for step [10]: 3.77 mins\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Training loss: 1.504789  [   64/  621] at step1\n",
      "Time took for step [1]: 0.38 mins\n",
      "Time took for step [2]: 0.76 mins\n",
      "Time took for step [3]: 1.09 mins\n",
      "Time took for step [4]: 1.45 mins\n",
      "Time took for step [5]: 1.84 mins\n",
      "Time took for step [6]: 2.18 mins\n",
      "Time took for step [7]: 2.55 mins\n",
      "Time took for step [8]: 2.94 mins\n",
      "Time took for step [9]: 3.28 mins\n",
      "Time took for step [10]: 3.52 mins\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Training loss: 1.378854  [   64/  621] at step1\n",
      "Time took for step [1]: 0.40 mins\n",
      "Time took for step [2]: 0.75 mins\n",
      "Time took for step [3]: 1.10 mins\n",
      "Time took for step [4]: 1.39 mins\n",
      "Time took for step [5]: 1.71 mins\n",
      "Time took for step [6]: 2.04 mins\n",
      "Time took for step [7]: 2.36 mins\n",
      "Time took for step [8]: 2.68 mins\n",
      "Time took for step [9]: 3.00 mins\n",
      "Time took for step [10]: 3.23 mins\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Training loss: 1.097391  [   64/  621] at step1\n",
      "Time took for step [1]: 0.32 mins\n",
      "Time took for step [2]: 0.68 mins\n",
      "Time took for step [3]: 1.02 mins\n",
      "Time took for step [4]: 1.34 mins\n",
      "Time took for step [5]: 1.70 mins\n",
      "Time took for step [6]: 2.07 mins\n",
      "Time took for step [7]: 2.42 mins\n",
      "Time took for step [8]: 2.75 mins\n",
      "Time took for step [9]: 3.10 mins\n",
      "Time took for step [10]: 3.35 mins\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Training loss: 1.277701  [   64/  621] at step1\n",
      "Time took for step [1]: 0.35 mins\n",
      "Time took for step [2]: 0.71 mins\n",
      "Time took for step [3]: 1.05 mins\n",
      "Time took for step [4]: 1.40 mins\n",
      "Time took for step [5]: 1.76 mins\n",
      "Time took for step [6]: 2.09 mins\n",
      "Time took for step [7]: 2.45 mins\n",
      "Time took for step [8]: 2.78 mins\n",
      "Time took for step [9]: 3.12 mins\n",
      "Time took for step [10]: 3.37 mins\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Training loss: 1.047881  [   64/  621] at step1\n",
      "Time took for step [1]: 0.35 mins\n",
      "Time took for step [2]: 0.69 mins\n",
      "Time took for step [3]: 1.02 mins\n",
      "Time took for step [4]: 1.37 mins\n",
      "Time took for step [5]: 1.75 mins\n",
      "Time took for step [6]: 2.09 mins\n",
      "Time took for step [7]: 2.45 mins\n",
      "Time took for step [8]: 2.81 mins\n",
      "Time took for step [9]: 3.19 mins\n",
      "Time took for step [10]: 3.43 mins\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Training loss: 0.920278  [   64/  621] at step1\n",
      "Time took for step [1]: 0.40 mins\n",
      "Time took for step [2]: 0.75 mins\n",
      "Time took for step [3]: 1.11 mins\n",
      "Time took for step [4]: 1.48 mins\n",
      "Time took for step [5]: 1.90 mins\n",
      "Time took for step [6]: 2.31 mins\n",
      "Time took for step [7]: 2.68 mins\n",
      "Time took for step [8]: 3.07 mins\n",
      "Time took for step [9]: 3.55 mins\n",
      "Time took for step [10]: 3.82 mins\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Training loss: 0.861080  [   64/  621] at step1\n",
      "Time took for step [1]: 0.45 mins\n",
      "Time took for step [2]: 0.92 mins\n",
      "Time took for step [3]: 1.37 mins\n",
      "Time took for step [4]: 1.83 mins\n",
      "Time took for step [5]: 2.20 mins\n",
      "Time took for step [6]: 2.66 mins\n",
      "Time took for step [7]: 3.16 mins\n",
      "Time took for step [8]: 3.67 mins\n",
      "Time took for step [9]: 4.04 mins\n",
      "Time took for step [10]: 4.32 mins\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Training loss: 0.782933  [   64/  621] at step1\n",
      "Time took for step [1]: 0.43 mins\n",
      "Time took for step [2]: 0.90 mins\n",
      "Time took for step [3]: 1.33 mins\n",
      "Time took for step [4]: 1.68 mins\n",
      "Time took for step [5]: 2.03 mins\n",
      "Time took for step [6]: 2.40 mins\n",
      "Time took for step [7]: 2.79 mins\n",
      "Time took for step [8]: 3.17 mins\n",
      "Time took for step [9]: 3.63 mins\n",
      "Time took for step [10]: 3.92 mins\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Training loss: 0.605880  [   64/  621] at step1\n",
      "Time took for step [1]: 0.37 mins\n",
      "Time took for step [2]: 0.72 mins\n",
      "Time took for step [3]: 1.13 mins\n",
      "Time took for step [4]: 1.51 mins\n",
      "Time took for step [5]: 1.85 mins\n",
      "Time took for step [6]: 2.16 mins\n",
      "Time took for step [7]: 2.51 mins\n",
      "Time took for step [8]: 2.83 mins\n",
      "Time took for step [9]: 3.16 mins\n",
      "Time took for step [10]: 3.40 mins\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Training loss: 0.799201  [   64/  621] at step1\n",
      "Time took for step [1]: 0.31 mins\n",
      "Time took for step [2]: 0.65 mins\n",
      "Time took for step [3]: 1.00 mins\n",
      "Time took for step [4]: 1.33 mins\n",
      "Time took for step [5]: 1.67 mins\n",
      "Time took for step [6]: 1.99 mins\n",
      "Time took for step [7]: 2.30 mins\n",
      "Time took for step [8]: 2.63 mins\n",
      "Time took for step [9]: 2.98 mins\n",
      "Time took for step [10]: 3.23 mins\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Training loss: 0.646597  [   64/  621] at step1\n",
      "Time took for step [1]: 0.35 mins\n",
      "Time took for step [2]: 0.71 mins\n",
      "Time took for step [3]: 1.06 mins\n",
      "Time took for step [4]: 1.37 mins\n",
      "Time took for step [5]: 1.67 mins\n",
      "Time took for step [6]: 1.99 mins\n",
      "Time took for step [7]: 2.33 mins\n",
      "Time took for step [8]: 2.68 mins\n",
      "Time took for step [9]: 3.01 mins\n",
      "Time took for step [10]: 3.28 mins\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Training loss: 0.743207  [   64/  621] at step1\n",
      "Time took for step [1]: 0.33 mins\n",
      "Time took for step [2]: 0.65 mins\n",
      "Time took for step [3]: 0.98 mins\n",
      "Time took for step [4]: 1.31 mins\n",
      "Time took for step [5]: 1.63 mins\n",
      "Time took for step [6]: 1.96 mins\n",
      "Time took for step [7]: 2.30 mins\n",
      "Time took for step [8]: 2.67 mins\n",
      "Time took for step [9]: 3.03 mins\n",
      "Time took for step [10]: 3.27 mins\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Training loss: 0.551504  [   64/  621] at step1\n",
      "Time took for step [1]: 0.32 mins\n",
      "Time took for step [2]: 0.73 mins\n",
      "Time took for step [3]: 1.29 mins\n",
      "Time took for step [4]: 1.87 mins\n",
      "Time took for step [5]: 2.32 mins\n",
      "Time took for step [6]: 2.76 mins\n",
      "Time took for step [7]: 3.37 mins\n",
      "Time took for step [8]: 3.90 mins\n",
      "Time took for step [9]: 4.48 mins\n",
      "Time took for step [10]: 4.82 mins\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Training loss: 0.637868  [   64/  621] at step1\n",
      "Time took for step [1]: 0.45 mins\n",
      "Time took for step [2]: 0.89 mins\n",
      "Time took for step [3]: 1.31 mins\n",
      "Time took for step [4]: 1.81 mins\n",
      "Time took for step [5]: 2.29 mins\n",
      "Time took for step [6]: 2.85 mins\n",
      "Time took for step [7]: 3.27 mins\n",
      "Time took for step [8]: 3.65 mins\n",
      "Time took for step [9]: 4.04 mins\n",
      "Time took for step [10]: 4.38 mins\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Training loss: 0.426773  [   64/  621] at step1\n",
      "Time took for step [1]: 0.53 mins\n",
      "Time took for step [2]: 0.95 mins\n",
      "Time took for step [3]: 1.45 mins\n",
      "Time took for step [4]: 1.90 mins\n",
      "Time took for step [5]: 2.36 mins\n",
      "Time took for step [6]: 2.94 mins\n",
      "Time took for step [7]: 3.56 mins\n",
      "Time took for step [8]: 3.99 mins\n",
      "Time took for step [9]: 4.43 mins\n",
      "Time took for step [10]: 4.74 mins\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(training_epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80ab9776-6b77-4ab6-bd92-80eb869f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './klanguage/'\n",
    "\n",
    "#save model\n",
    "torch.save(model, PATH + 'model.pt')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0177351-46fa-4a7c-96ea-6dae07d8ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(PATH + 'model.pt')\n",
    "val_loop(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af2deeaf-b22a-4004-bf8c-497ace209149",
   "metadata": {},
   "outputs": [],
   "source": [
    "testw(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f954469-67dc-408e-bd8b-f2d014ba5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"MachineLearning2 A3\",\n",
    "    # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    name=\"experiment\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": training_epochs\n",
    "    }\n",
    "    \n",
    "    )\n",
    "    global train_loss, train_acc, validation_loss, validation_acc\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # train_acc, validation_loss, validation_acc, sample_batch, sample_img, images = 0\n",
    "    model = CNN()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.005, momentum=0.9)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_validation_acc = 0.0\n",
    "    for t in range(training_epochs):\n",
    "        \n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss, train_acc = train_loop(model, loss_fn, optimizer)\n",
    "        validation_loss, validation_acc = val_loop(model, loss_fn)\n",
    "        \n",
    "        sample_batch, _ = next(iter(train_loader))\n",
    "        sample_img = to_pil_image(sample_batch[0])\n",
    "        sample_img = wandb.Image( # single image\n",
    "        sample_img,\n",
    "        caption=\"sample image\"\n",
    "        )\n",
    "        \n",
    "        images = [to_pil_image(image) for image in sample_batch[:5]] # multiple images\n",
    "        \n",
    "        wandb.log({\n",
    "          \"train_acc\": train_acc,\n",
    "          \"train_loss\": train_loss,\n",
    "          \"validation_acc\": validation_acc,\n",
    "          \"validation_loss\": validation_loss,\n",
    "          \"example\": sample_img,\n",
    "          \"examples\": [wandb.Image(image) for image in images],\n",
    "          })\n",
    "\n",
    "        if validation_acc > best_validation_acc:\n",
    "            torch.save(model.state_dict(), './best.pth')\n",
    "\n",
    "    print(\"Done!\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb0ce0db-0758-43ab-bd4c-6c4f0838a2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3qnw1lyi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.09629196592617338, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment</strong> at: <a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3/runs/3qnw1lyi' target=\"_blank\">https://wandb.ai/machine_learning2/MachineLearning2%20A3/runs/3qnw1lyi</a><br/> View job at <a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNjA1MjE4MQ==/version_details/v0' target=\"_blank\">https://wandb.ai/machine_learning2/MachineLearning2%20A3/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNjA1MjE4MQ==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231228_203123-3qnw1lyi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3qnw1lyi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd77b79195449c8b51cad4899989f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011143683188897234, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jason/Projects/MachineLearningProjects/wandb/run-20231228_203746-4xl0n2nx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3/runs/4xl0n2nx' target=\"_blank\">experiment</a></strong> to <a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3' target=\"_blank\">https://wandb.ai/machine_learning2/MachineLearning2%20A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3/runs/4xl0n2nx' target=\"_blank\">https://wandb.ai/machine_learning2/MachineLearning2%20A3/runs/4xl0n2nx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 10.3%, Avg loss: 0.370562 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 13.5%, Avg loss: 0.108317 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 19.5%, Avg loss: 0.356614 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 7.7%, Avg loss: 0.109169 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 26.2%, Avg loss: 0.347882 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 16.8%, Avg loss: 0.108808 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 27.1%, Avg loss: 0.342239 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 15.5%, Avg loss: 0.108474 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 30.4%, Avg loss: 0.336298 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 15.5%, Avg loss: 0.108591 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 36.4%, Avg loss: 0.328497 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 12.9%, Avg loss: 0.108942 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 36.9%, Avg loss: 0.322499 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.109204 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 41.1%, Avg loss: 0.316164 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 7.7%, Avg loss: 0.109227 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 42.2%, Avg loss: 0.312620 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 13.5%, Avg loss: 0.108679 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 44.6%, Avg loss: 0.305943 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 11.0%, Avg loss: 0.109644 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 45.2%, Avg loss: 0.301005 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 7.1%, Avg loss: 0.109765 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 48.1%, Avg loss: 0.296528 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.108060 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.292446 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.109244 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.289134 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 10.3%, Avg loss: 0.109032 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 50.9%, Avg loss: 0.284383 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 11.6%, Avg loss: 0.109473 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.280335 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.109745 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 49.3%, Avg loss: 0.276301 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.108712 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.271346 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 11.6%, Avg loss: 0.108908 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 52.2%, Avg loss: 0.268088 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.108609 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.263216 \n",
      "\n",
      "Validation Start\n",
      "---------------------\n",
      "Validation Error: \n",
      " Accuracy: 9.0%, Avg loss: 0.109099 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='13.732 MB of 13.732 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▂▃▃▄▅▅▅▆▆▆▇▆▆▇▇▇▇▇█</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>validation_acc</td><td>▆▁█▇▇▅▆▁▆▄▁▆▆▃▄▆▆▄▆▂</td></tr><tr><td>validation_loss</td><td>▂▆▄▃▃▅▆▆▄██▁▆▅▇█▄▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.58454</td></tr><tr><td>train_loss</td><td>0.26322</td></tr><tr><td>validation_acc</td><td>0.09032</td></tr><tr><td>validation_loss</td><td>0.1091</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment</strong> at: <a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3/runs/4xl0n2nx' target=\"_blank\">https://wandb.ai/machine_learning2/MachineLearning2%20A3/runs/4xl0n2nx</a><br/> View job at <a href='https://wandb.ai/machine_learning2/MachineLearning2%20A3/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNjA1MjE4MQ==/version_details/v1' target=\"_blank\">https://wandb.ai/machine_learning2/MachineLearning2%20A3/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNjA1MjE4MQ==/version_details/v1</a><br/>Synced 6 W&B file(s), 120 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231228_203746-4xl0n2nx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c126b-69fc-40e9-af68-888e06d5f2c4",
   "metadata": {},
   "source": [
    "In this course, we will learn functional programming paradigm and functional programming languages (ML and C++). We will learn important concepts in programming languages, such as tail recursion, lexical scopes, currying, and lazy evaluation. We will also learn parallel programming model and the constructs for parallel programming.\n",
    "\n",
    "NOTICE:\n",
    "  * The textbooks are optional.\n",
    "  * The course materials are based on those of Programming Language course in UW (by Dan Grossman).\n",
    "\n",
    "Course Objectives:\n",
    "  * Understand and internalize different programming paradigms, such as functional and object-oriented programming.\n",
    "  * Develop the skills to quickly learn new programming language.\n",
    "  * Learn to understand the power and elegance of programming languages and their constructs.\n",
    "  * Be reasonably proficient in ML, C++, and CUDA.\n",
    "\n",
    "\n",
    "Course Topics for each week:\n",
    "\n",
    "1.\tSyntax vs. semantics vs. idioms vs. libraries vs. tools \n",
    "2.\tML basics (bindings, conditionals, records, functions) \n",
    "3.\tRecursive functions and recursive types \n",
    "4.\tBenefits of no mutation \n",
    "5.\tAlgebraic datatypes, pattern matching \n",
    "6.\tTail recursion \n",
    "7.\tHigher-order functions; closures \n",
    "8.\tLexical scope \n",
    "9.\tCurrying \n",
    "10.\tSyntactic sugar \n",
    "11.\tEquivalence and effects \n",
    "12.\tParametric polymorphism and container types \n",
    "13.\tType inference \n",
    "14.\tAbstract types and modules \n",
    "15.\tC++ some fundamentals\n",
    "16.\tDynamic vs. static typing \n",
    "17.\tLaziness, streams, and memoization \n",
    "18.\tImplementing languages, especially higher-order functions \n",
    "19.\tMacros \n",
    "20.\tEval \n",
    "21.\tAbstract types via dynamic type-creation and simple contracts \n",
    "22.\tProgramming model for parallelism\n",
    "23.\tCuda Basics\n",
    "24.\tCuda Programming and applications\n",
    "\n",
    "Learn functional programming model\n",
    "\n",
    "Learn ML and C++ (functional paradigm)\n",
    "\n",
    "Learn parallel programming (CUDA)\n",
    "Functional Programming\n",
    "Parallel Programming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
